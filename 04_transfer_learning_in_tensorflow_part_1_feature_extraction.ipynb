{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObwiuiGkZb87"
      },
      "source": [
        "# 04. Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
        "\n",
        "We've built a bunch of convolutional neural networks from scratch and they all seem to be learning, however, there is still plenty of room for improvement.\n",
        "\n",
        "To improve our model(s), we could spend a while trying different configurations, adding more layers, changing the learning rate, adjusting the number of neurons per layer and more.\n",
        "\n",
        "However, doing this is very time consuming.\n",
        "\n",
        "Luckily, there's a technique we can use to save time.\n",
        "\n",
        "It's called **transfer learning**, in other words, taking the patterns (also called weights) another model has learned from another problem and using them for our own problem.\n",
        "\n",
        "There are two main benefits to using transfer learning:\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has **already learned** patterns on similar data to our own. This often results in achieving great results with less custom data.\n",
        "\n",
        "What this means is, instead of hand-crafting our own neural network architectures or building them from scratch, we can utilise models which have worked for others.\n",
        "\n",
        "And instead of training our own models from scratch on our own datasets, we can take the patterns a model has learned from datasets such as [ImageNet](http://www.image-net.org/) (millions of images of different objects) and use them as the foundation of our own. Doing this often leads to getting great results with less data.\n",
        "\n",
        "Over the next few notebooks, we'll see the power of transfer learning in action.\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "We're going to go through the following with TensorFlow:\n",
        "\n",
        "- Introduce transfer learning (a way to beat all of our old self-built models)\n",
        "- Using a smaller dataset to experiment faster (10% of training samples of 10 classes of food)\n",
        "- Build a transfer learning feature extraction model using TensorFlow Hub\n",
        "- Introduce the TensorBoard callback to track model training results\n",
        "- Compare model results using TensorBoard\n",
        "\n",
        "## How you can use this notebook\n",
        "\n",
        "You can read through the descriptions and the code (it should all run, except for the cells which error on purpose), but there's a better option.\n",
        "\n",
        "Write all of the code yourself.\n",
        "\n",
        "Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?\n",
        "\n",
        "You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n",
        "\n",
        "Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to **write more code**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTWetPM7AWfY"
      },
      "source": [
        "## Using a GPU\n",
        "\n",
        "To begin, let's check to see if we're using a GPU. Using a GPU will make sure our model trains faster than using just a CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq4kxIpQMpZT",
        "outputId": "5a53217a-7674-437c-df90-8e9ae37a54ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed May  4 09:18:15 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.68.02    Driver Version: 510.68.02    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:42:00.0  On |                  N/A |\n",
            "| 41%   55C    P0    98W / 300W |  10272MiB / 11264MiB |     21%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A       951      G   /usr/lib/Xorg                     505MiB |\n",
            "|    0   N/A  N/A      1241      G   picom                             183MiB |\n",
            "|    0   N/A  N/A      1589      G   ...RendererForSitePerProcess      137MiB |\n",
            "|    0   N/A  N/A      2084      C   ...nda3/envs/venv/bin/python     9239MiB |\n",
            "|    0   N/A  N/A      2474      G   ...916517060303988587,131072      169MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Are we using a GPU?\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol3NDTVlRLSv"
      },
      "source": [
        "If the cell above doesn't output something which looks like:\n",
        "\n",
        "```\n",
        "Fri Sep  4 03:35:21 2020       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "|                               |                      |                 ERR! |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```\n",
        "\n",
        "Go to Runtime -> Change Runtime Type -> Hardware Accelerator and select \"GPU\", then rerun the cell above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NY09457NKv4"
      },
      "source": [
        "## Transfer leanring with TensorFlow Hub: Getting great results with 10% of the data\n",
        "\n",
        "If you've been thinking, \"surely someone else has spent the time crafting the right model for the job...\" then you're in luck. \n",
        "\n",
        "For many of the problems you'll want to use deep learning for, chances are, a working model already exists.\n",
        "\n",
        "And the good news is, you can access many of them on TensorFlow Hub.\n",
        "\n",
        "[TensorFlow Hub](https://tfhub.dev/) is a repository for existing model components. It makes it so you can import and use a fully trained model with as little as a URL.\n",
        "\n",
        "Now, I really want to demonstrate the power of transfer learning to you.\n",
        "\n",
        "To do so, what if I told you we could get much of the same results (or better) than our best model has gotten so far with only 10% of the original data, in other words, 10x less data.\n",
        "\n",
        "This seems counterintuitive right?\n",
        "\n",
        "Wouldn't you think more examples of what a picture of food looked like led to better results?\n",
        "\n",
        "And you'd be right if you thought so, generally, more data leads to better results.\n",
        "\n",
        "However, what if you didn't have more data? What if instead of 750 images per class, you had 75 images per class?\n",
        "\n",
        "Collecting 675 more images of a certain class could take a long time.\n",
        "\n",
        "So this is where another major benefit of transfer learning comes in.\n",
        "\n",
        "**Transfer learning often allows you to get great results with less data.**\n",
        "\n",
        "But don't just take my word for it. Let's download a subset of the data we've been using, namely 10% of the training data from the `10_food_classes` dataset and use it to train a food image classifier on.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png)\n",
        "*What we're working towards building. Taking a pre-trained model and adding our own custom layers on top, extracting all of the underlying patterns learned on another dataset our own images.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIwVrX6vXb4z"
      },
      "source": [
        "## Downloading and becoming one with the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwWwP657Szfv",
        "outputId": "46b1d719-f47b-4918-92e8-92a18c1935b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-04 09:18:15--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 2607:f8b0:400a:801::2010, 2607:f8b0:400a:803::2010, 2607:f8b0:400a:807::2010, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|2607:f8b0:400a:801::2010|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zip.1â€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  78.2MB/s    in 2.1s    \n",
            "\n",
            "2022-05-04 09:18:17 (78.2 MB/s) - â€˜10_food_classes_10_percent.zip.1â€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get data (10% of labels)\n",
        "import zipfile\n",
        "\n",
        "# Download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agzJYtfFBl6I",
        "outputId": "f347e60c-72ed-49c6-e706-c8be3439bea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n"
          ]
        }
      ],
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0r-zyagV7Qa"
      },
      "source": [
        "Notice how each of the training directories now has 75 images rather than 750 images. This is key to demonstrating how well transfer learning can perform with less labelled images.\n",
        "\n",
        "The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EES-NoeaXfYT"
      },
      "source": [
        "## Creating data loaders (preparing the data)\n",
        "\n",
        "Now we've downloaded the data, let's use the [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class along with the `flow_from_directory` method to load in our images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAp0GN60S-rK",
        "outputId": "bb4a2dc3-fad9-416b-b81a-b2a0d3abcb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QWuVeSvQPoK"
      },
      "source": [
        "Excellent! Loading in the data we can see we've got 750 images in the training dataset belonging to 10 classes (75 per class) and 2500 images in the test set belonging to 10 classes (250 per class)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qcwii2uYjOx"
      },
      "source": [
        "## Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "Before we build a model, there's an important concept we're going to get familiar with because it's going to play a key role in our future model building experiments.\n",
        "\n",
        "And that concept is **callbacks**.\n",
        "\n",
        "[Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n",
        "* [**Experiment tracking with TensorBoard**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) - log the performance of multiple models and then view and compare these models in a visual way on [TensorBoard](https://www.tensorflow.org/tensorboard) (a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data.\n",
        "* [**Model checkpointing**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting.\n",
        "* [**Early stopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.\n",
        "\n",
        "We'll explore each of these overtime but for this notebook, we'll see how the TensorBoard callback can be used.\n",
        "\n",
        "The TensorBoard callback can be accessed using [`tf.keras.callbacks.TensorBoard()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard). \n",
        "\n",
        "Its main functionality is saving a model's training performance metrics to a specified `log_dir`.\n",
        "\n",
        "By default, logs are recorded every epoch using the `update_freq='epoch'` parameter. This is a good default since tracking model performance too often can slow down model training.\n",
        "\n",
        "To track our modelling experiments using TensorBoard, let's create a function which creates a TensorBoard callback for us.\n",
        "\n",
        "> ðŸ”‘ **Note:** We create a function for creating a TensorBoard callback because as we'll see later on, each model needs its own TensorBoard callback instance (so the function will create a new one each time it's run).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2yamhJ8xJA5x"
      },
      "outputs": [],
      "source": [
        "# Create tensorboard callback (functionized because need to create a new one for each model)\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11TjBJQXdCyZ"
      },
      "source": [
        "Because you're likely to run multiple experiments, it's a good idea to be able to track them in some way.\n",
        "\n",
        "In our case, our function saves a model's performance logs to a directory named `[dir_name]/[experiment_name]/[current_timestamp]`, where:\n",
        "* `dir_name` is the overall logs directory\n",
        "* `experiment_name` is the particular experiment\n",
        "* `current_timestamp` is the time the experiment started based on Python's [`datetime.datetime().now()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.now)\n",
        "\n",
        "> ðŸ”‘ **Note:** Depending on your use case, the above experimenting tracking naming method may work or you might require something more specific. The good news is, the TensorBoard callback makes it easy to track modelling logs as long as you specify where to track them. So you can get as creative as you like with how you name your experiments, just make sure you or your team can understand them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UP8vA_nYoI7"
      },
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from [TensorFlow Hub](https://tfhub.dev/).\n",
        "\n",
        "In fact, we're going to use two models from TensorFlow Hub:\n",
        "1. [ResNetV2](https://arxiv.org/abs/1603.05027) -  a state of the art computer vision model architecture from 2016.\n",
        "2. [EfficientNet](https://arxiv.org/abs/1905.11946) - a state of the art computer vision architecture from 2019.\n",
        "\n",
        "State of the art means that at some point, both of these models have achieved the lowest error rate on [ImageNet (ILSVRC-2012-CLS)](http://www.image-net.org/), the gold standard of computer vision benchmarks.\n",
        "\n",
        "You might be wondering, how do you find these models on TensorFlow Hub?\n",
        "\n",
        "Here are the steps I took:\n",
        "\n",
        "1. Go to [tfhub.dev](https://tfhub.dev/).\n",
        "2. Choose your problem domain, e.g. \"Image\" (we're using food images).\n",
        "3. Select your TF version, which in our case is TF2.\n",
        "4. Remove all \"Problem domanin\" filters except for the problem you're working on. \n",
        "  * **Note:** \"Image feature vector\" can be used alongside almost any problem, we'll get to this soon.\n",
        "5. The models listed are all models which could potentially be used for your problem.\n",
        "\n",
        "> ðŸ¤” **Question:** *I see many options for image classification models, how do I know which is best?*\n",
        "\n",
        "You can see a list of state of the art models on [paperswithcode.com](https://www.paperswithcode.com), a resource for collecting the latest in deep learning paper results which have code implementations for the findings they report.\n",
        "\n",
        "Since we're working with images, our target are the [models which perform best on ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet).\n",
        "\n",
        "You'll probably find not all of the model architectures listed on paperswithcode appear on TensorFlow Hub. And this is okay, we can still use what's available.\n",
        "\n",
        "To find our models, let's narrow down our search using the Architecture tab.\n",
        "\n",
        "6. Select the Architecture tab on TensorFlow Hub and you'll see a dropdown menu of architecture names appear. \n",
        "  * The rule of thumb here is generally, names with larger numbers means better performing models. For example, EfficientNetB4 performs better than EfficientNetB0.\n",
        "    * However, the tradeoff with larger numbers can mean they take longer to compute. \n",
        "7. Select EfficientNetB0 and you should see [something like the following](https://tfhub.dev/s?module-type=image-classification,image-feature-vector&network-architecture=efficientnet-b0&tf-version=tf2):\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-tensorflow-hub-efficientnetb0.png)\n",
        "8. Clicking the one titled \"[efficientnet/b0/feature-vector](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1)\" brings us to a page with a button that says \"Copy URL\". That URL is what we can use to harness the power of EfficientNetB0.\n",
        "  * Copying the URL should give you something like this: https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n",
        "\n",
        "> ðŸ¤” **Question:** *I thought we were doing image classification, why do we choose feature vector and not classification?*\n",
        "\n",
        "Great observation. This is where the differnet types of transfer learning come into play, as is, feature extraction and fine-tuning.\n",
        "\n",
        "1. **\"As is\" transfer learning** is when you take a pretrained model as it is and apply it to your task without any changes. \n",
        "\n",
        "  * For example, many computer vision models are pretrained on the ImageNet dataset which contains 1000 different classes of images. This means passing a single image to this model will produce 1000 different prediction probability values (1 for each class). \n",
        "\n",
        "    * This is helpful if you have 1000 classes of image you'd like to classify and they're all the same as the ImageNet classes, however, it's not helpful if you want to classify only a small subset of classes (such as 10 different kinds of food). Model's with `\"/classification\"` in their name on TensorFlow Hub provide this kind of functionality.\n",
        "\n",
        "2. **Feature extraction transfer learning** is when you take the underlying patterns (also called weights) a pretrained model has learned and adjust its outputs to be more suited to your problem. \n",
        "\n",
        "  * For example, say the pretrained model you were using had 236 different layers (EfficientNetB0 has 236 layers), but the top layer outputs 1000 classes because it was pretrained on ImageNet. To adjust this to your own problem, you might remove the original activation layer and replace it with your own but with the right number of output classes. The important part here is that **only the top few layers become trainable, the rest remain frozen**. \n",
        "\n",
        "    * This way all the underlying patterns remain in the rest of the layers and you can utilise them for your own problem. This kind of transfer learning is very helpful when your data is similar to the data a model has been pretrained on.\n",
        "\n",
        "3. **Fine-tuning transfer learning** is when you take the underlying patterns (also called weights) of a pretrained model and adjust (fine-tune) them to your own problem. \n",
        "\n",
        "    * This usually means training **some, many or all** of the layers in the pretrained model. This is useful when you've got a large dataset (e.g. 100+ images per class) where your data is slightly different to the data the original model was trained on.\n",
        "\n",
        "A common workflow is to \"freeze\" all of the learned patterns in the bottom layers of a pretrained model so they're untrainable. And then train the top 2-3 layers of so the pretrained model can adjust its outputs to your custom data (**feature extraction**).\n",
        "\n",
        "After you've trained the top 2-3 layers, you can then gradually \"unfreeze\" more and more layers and run the training process on your own data to further **fine-tune** the pretrained model.\n",
        "\n",
        "> ðŸ¤” **Question:** *Why train only the top 2-3 layers in feature extraction?*\n",
        "\n",
        "The lower a layer is in a computer vision model as in, the closer it is to the input layer, the larger the features it learn. For example, a bottom layer in a computer vision model to identify images of cats or dogs might learn the outline of legs, where as, layers closer to the output might learn the shape of teeth. Often, you'll want the larger features (learned patterns are also called features) to remain, since these are similar for both animals, where as, the differences remain in the more fine-grained features.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png)\n",
        "*The different kinds of transfer learning. An original model, a feature extraction model (only top 2-3 layers change) and a fine-tuning model (many or all of original model get changed).*\n",
        "\n",
        "Okay, enough talk, let's see this in action. Once we do, we'll explain what's happening.\n",
        "\n",
        "First we'll import TensorFlow and TensorFlow Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xsoE9nUJNN6s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvGge7Xevt_F"
      },
      "source": [
        "Now we'll get the feature vector URLs of two common computer vision architectures, [EfficientNetB0 (2019)](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1) and [ResNetV250 (2016)](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4) from TensorFlow Hub using the steps above.\n",
        "\n",
        "We're getting both of these because we're going to compare them to see which performs better on our data.\n",
        "\n",
        "> ðŸ”‘ **Note:** Comparing different model architecture performance on the same data is a very common practice. The simple reason is because you want to know which model performs best for your problem.\n",
        "\n",
        "> **Update:** As of 14 August 2021, [EfficientNet V2 pretrained models are available on TensorFlow Hub](https://tfhub.dev/google/collections/efficientnet_v2/1). The original code in this notebook uses EfficientNet V1, it has been left unchanged. In [my experiments with this dataset](https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166), V1 outperforms V2. Best to experiment with your own data and see what suits you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LZfUivHxOCbP"
      },
      "outputs": [],
      "source": [
        "# Resnet 50 V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# Original: EfficientNetB0 feature vector (version 1)\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "# # New: EfficientNetB0 feature vector (version 2)\n",
        "# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdwjFaCRwdCX"
      },
      "source": [
        "These URLs link to a saved pretrained model on TensorFlow Hub.\n",
        "\n",
        "When we use them in our model, the model will automatically be downloaded for us to use.\n",
        "\n",
        "To do this, we can use the [`KerasLayer()`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) model inside the TensorFlow hub library.\n",
        "\n",
        "Since we're going to be comparing two models, to save ourselves code, we'll create a function `create_model()`. This function will take a model's TensorFlow Hub URL, instatiate a Keras Sequential model with the appropriate number of output layers and return the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p7vXoqSjId0f"
      },
      "outputs": [],
      "source": [
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "  \n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, # freeze the underlying patterns\n",
        "                                           name='feature_extraction_layer',\n",
        "                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n",
        "  \n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "    feature_extractor_layer, # use the feature extraction layer as the base\n",
        "    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer      \n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IirF2Ohlz-6i"
      },
      "source": [
        "Great! Now we've got a function for creating a model, we'll use it to first create a model using the ResNetV250 architecture as our feature extraction layer.\n",
        "\n",
        "Once the model is instantiated, we'll compile it using `categorical_crossentropy` as our loss function, the Adam optimizer and accuracy as our metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-KVRwwbDT-HL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-04 09:18:24.088887: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-05-04 09:18:24.523013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 165 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile\n",
        "resnet_model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZinVcxBi0jsv"
      },
      "source": [
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-resnet-feature-extractor.png)\n",
        "*What our current model looks like. A ResNet50V2 backbone with a custom dense layer on top (10 classes instead of 1000 ImageNet classes). **Note:** The Image shows ResNet34 instead of ResNet50. **Image source:** https://arxiv.org/abs/1512.03385.*\n",
        "\n",
        "Beautiful. Time to fit the model.\n",
        "\n",
        "We've got the training data ready in `train_data_10_percent` as well as the test data saved as `test_data`.\n",
        "\n",
        "But before we call the fit function, there's one more thing we're going to add, a callback. More specifically, a TensorBoard callback so we can track the performance of our model on TensorBoard.\n",
        "\n",
        "We can add a callback to our model by using the `callbacks` parameter in the fit function.\n",
        "\n",
        "In our case, we'll pass the `callbacks` parameter the `create_tensorboard_callback()` we created earlier with some specific inputs so we know what experiments we're running.\n",
        "\n",
        "Let's keep this experiment short and train for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GTl0fwE0Hx6",
        "outputId": "4cf373f4-7143-45b0-ddfc-d1cb009e555a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20220504-091826\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-04 09:18:39.288638: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 98.00MiB (rounded to 102760448)requested by op sequential/feature_extraction_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/predict/resnet_v2_50/conv1/Conv2D\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2022-05-04 09:18:39.288703: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
            "2022-05-04 09:18:39.288715: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 61, Chunks in use: 60. 15.2KiB allocated for chunks. 15.0KiB in use in bin. 7.7KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288723: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 32, Chunks in use: 32. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288730: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 66, Chunks in use: 66. 66.5KiB allocated for chunks. 66.5KiB in use in bin. 66.3KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288738: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 45, Chunks in use: 45. 90.0KiB allocated for chunks. 90.0KiB in use in bin. 90.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288745: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 31, Chunks in use: 31. 124.0KiB allocated for chunks. 124.0KiB in use in bin. 124.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288753: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 16, Chunks in use: 16. 128.0KiB allocated for chunks. 128.0KiB in use in bin. 128.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288760: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288767: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 36.8KiB allocated for chunks. 36.8KiB in use in bin. 36.8KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288775: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 8, Chunks in use: 8. 544.0KiB allocated for chunks. 544.0KiB in use in bin. 544.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288782: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 5, Chunks in use: 5. 717.2KiB allocated for chunks. 717.2KiB in use in bin. 640.0KiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288789: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 7, Chunks in use: 7. 1.75MiB allocated for chunks. 1.75MiB in use in bin. 1.75MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288796: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 6, Chunks in use: 6. 3.25MiB allocated for chunks. 3.25MiB in use in bin. 3.25MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288803: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 11, Chunks in use: 11. 11.00MiB allocated for chunks. 11.00MiB in use in bin. 11.00MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288810: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 8, Chunks in use: 8. 17.50MiB allocated for chunks. 17.50MiB in use in bin. 17.50MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288818: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 5, Chunks in use: 5. 20.00MiB allocated for chunks. 20.00MiB in use in bin. 20.00MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288825: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 4, Chunks in use: 4. 35.00MiB allocated for chunks. 35.00MiB in use in bin. 35.00MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288833: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 0. 37.75MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288841: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 37.16MiB allocated for chunks. 37.16MiB in use in bin. 19.37MiB client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288847: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288853: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288860: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2022-05-04 09:18:39.288867: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 98.00MiB was 64.00MiB, Chunk State: \n",
            "2022-05-04 09:18:39.288872: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 173146112\n",
            "2022-05-04 09:18:39.288881: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988000000 of size 1280 next 1\n",
            "2022-05-04 09:18:39.288886: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988000500 of size 256 next 2\n",
            "2022-05-04 09:18:39.288891: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988000600 of size 262144 next 3\n",
            "2022-05-04 09:18:39.288896: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988040600 of size 256 next 4\n",
            "2022-05-04 09:18:39.288902: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988040700 of size 8192 next 5\n",
            "2022-05-04 09:18:39.288907: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988042700 of size 256 next 6\n",
            "2022-05-04 09:18:39.288912: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988042800 of size 2048 next 7\n",
            "2022-05-04 09:18:39.288917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988043000 of size 2048 next 8\n",
            "2022-05-04 09:18:39.288922: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988043800 of size 4096 next 9\n",
            "2022-05-04 09:18:39.288928: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988044800 of size 1024 next 10\n",
            "2022-05-04 09:18:39.288933: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988044c00 of size 2048 next 11\n",
            "2022-05-04 09:18:39.288938: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988045400 of size 256 next 12\n",
            "2022-05-04 09:18:39.288943: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988045500 of size 1024 next 13\n",
            "2022-05-04 09:18:39.288948: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988045900 of size 256 next 14\n",
            "2022-05-04 09:18:39.288953: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988045a00 of size 512 next 15\n",
            "2022-05-04 09:18:39.288958: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988045c00 of size 512 next 16\n",
            "2022-05-04 09:18:39.288963: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988045e00 of size 589824 next 17\n",
            "2022-05-04 09:18:39.288968: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9880d5e00 of size 2048 next 18\n",
            "2022-05-04 09:18:39.288973: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9880d6600 of size 1024 next 19\n",
            "2022-05-04 09:18:39.288978: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9880d6a00 of size 1024 next 20\n",
            "2022-05-04 09:18:39.288984: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9880d6e00 of size 1048576 next 21\n",
            "2022-05-04 09:18:39.288989: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9881d6e00 of size 1024 next 22\n",
            "2022-05-04 09:18:39.288994: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9881d7200 of size 512 next 23\n",
            "2022-05-04 09:18:39.289000: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9881d7400 of size 1048576 next 24\n",
            "2022-05-04 09:18:39.289005: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9882d7400 of size 4194304 next 25\n",
            "2022-05-04 09:18:39.289010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9886d7400 of size 1024 next 26\n",
            "2022-05-04 09:18:39.289015: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9886d7800 of size 4096 next 27\n",
            "2022-05-04 09:18:39.289020: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9886d8800 of size 8192 next 28\n",
            "2022-05-04 09:18:39.289025: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9886da800 of size 65536 next 29\n",
            "2022-05-04 09:18:39.289030: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9886ea800 of size 131072 next 30\n",
            "2022-05-04 09:18:39.289035: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98870a800 of size 1024 next 31\n",
            "2022-05-04 09:18:39.289041: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98870ac00 of size 1024 next 32\n",
            "2022-05-04 09:18:39.289046: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98870b000 of size 2359296 next 33\n",
            "2022-05-04 09:18:39.289051: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894b000 of size 4096 next 34\n",
            "2022-05-04 09:18:39.289056: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894c000 of size 1024 next 35\n",
            "2022-05-04 09:18:39.289061: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894c400 of size 2048 next 36\n",
            "2022-05-04 09:18:39.289066: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894cc00 of size 8192 next 37\n",
            "2022-05-04 09:18:39.289071: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894ec00 of size 1024 next 38\n",
            "2022-05-04 09:18:39.289076: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894f000 of size 2048 next 39\n",
            "2022-05-04 09:18:39.289081: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894f800 of size 512 next 40\n",
            "2022-05-04 09:18:39.289086: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98894fa00 of size 2048 next 41\n",
            "2022-05-04 09:18:39.289091: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988950200 of size 1024 next 42\n",
            "2022-05-04 09:18:39.289096: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988950600 of size 262144 next 43\n",
            "2022-05-04 09:18:39.289101: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988990600 of size 512 next 44\n",
            "2022-05-04 09:18:39.289106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988990800 of size 262144 next 45\n",
            "2022-05-04 09:18:39.289111: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d0800 of size 2048 next 46\n",
            "2022-05-04 09:18:39.289116: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d1000 of size 1024 next 47\n",
            "2022-05-04 09:18:39.289121: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d1400 of size 1024 next 48\n",
            "2022-05-04 09:18:39.289126: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d1800 of size 1024 next 49\n",
            "2022-05-04 09:18:39.289131: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d1c00 of size 1024 next 50\n",
            "2022-05-04 09:18:39.289136: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d2000 of size 8192 next 51\n",
            "2022-05-04 09:18:39.289141: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889d4000 of size 147456 next 52\n",
            "2022-05-04 09:18:39.289146: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb9889f8000 of size 65536 next 53\n",
            "2022-05-04 09:18:39.289151: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a08000 of size 2048 next 54\n",
            "2022-05-04 09:18:39.289156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a08800 of size 1024 next 55\n",
            "2022-05-04 09:18:39.289161: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a08c00 of size 4096 next 56\n",
            "2022-05-04 09:18:39.289166: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a09c00 of size 1024 next 57\n",
            "2022-05-04 09:18:39.289171: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a0a000 of size 256 next 58\n",
            "2022-05-04 09:18:39.289177: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a0a100 of size 512 next 59\n",
            "2022-05-04 09:18:39.289182: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a0a300 of size 2048 next 60\n",
            "2022-05-04 09:18:39.289187: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a0ab00 of size 512 next 61\n",
            "2022-05-04 09:18:39.289192: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a0ad00 of size 262144 next 62\n",
            "2022-05-04 09:18:39.289198: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a4ad00 of size 1024 next 63\n",
            "2022-05-04 09:18:39.289203: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a4b100 of size 4096 next 64\n",
            "2022-05-04 09:18:39.289208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a4c100 of size 1024 next 65\n",
            "2022-05-04 09:18:39.289213: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988a4c500 of size 1048576 next 66\n",
            "2022-05-04 09:18:39.289218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988b4c500 of size 2048 next 67\n",
            "2022-05-04 09:18:39.289224: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988b4cd00 of size 2048 next 68\n",
            "2022-05-04 09:18:39.289229: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988b4d500 of size 1048576 next 69\n",
            "2022-05-04 09:18:39.289234: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c4d500 of size 2048 next 70\n",
            "2022-05-04 09:18:39.289239: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c4dd00 of size 8192 next 71\n",
            "2022-05-04 09:18:39.289245: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c4fd00 of size 1024 next 72\n",
            "2022-05-04 09:18:39.289250: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c50100 of size 2048 next 73\n",
            "2022-05-04 09:18:39.289255: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c50900 of size 512 next 74\n",
            "2022-05-04 09:18:39.289260: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c50b00 of size 1024 next 75\n",
            "2022-05-04 09:18:39.289265: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c50f00 of size 1024 next 76\n",
            "2022-05-04 09:18:39.289270: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c51300 of size 1024 next 77\n",
            "2022-05-04 09:18:39.289275: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c51700 of size 4096 next 78\n",
            "2022-05-04 09:18:39.289280: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c52700 of size 4096 next 79\n",
            "2022-05-04 09:18:39.289285: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c53700 of size 1024 next 80\n",
            "2022-05-04 09:18:39.289290: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c53b00 of size 2048 next 81\n",
            "2022-05-04 09:18:39.289295: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c54300 of size 256 next 82\n",
            "2022-05-04 09:18:39.289301: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c54400 of size 512 next 83\n",
            "2022-05-04 09:18:39.289306: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c54600 of size 65536 next 84\n",
            "2022-05-04 09:18:39.289312: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c64600 of size 256 next 85\n",
            "2022-05-04 09:18:39.289317: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c64700 of size 2048 next 86\n",
            "2022-05-04 09:18:39.289322: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c64f00 of size 1024 next 87\n",
            "2022-05-04 09:18:39.289327: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988c65300 of size 2097152 next 88\n",
            "2022-05-04 09:18:39.289332: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e65300 of size 2048 next 89\n",
            "2022-05-04 09:18:39.289337: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e65b00 of size 2048 next 90\n",
            "2022-05-04 09:18:39.289342: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e66300 of size 2048 next 91\n",
            "2022-05-04 09:18:39.289347: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e66b00 of size 1024 next 92\n",
            "2022-05-04 09:18:39.289352: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e66f00 of size 256 next 93\n",
            "2022-05-04 09:18:39.289357: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e67000 of size 4096 next 94\n",
            "2022-05-04 09:18:39.289362: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e68000 of size 4096 next 95\n",
            "2022-05-04 09:18:39.289367: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e69000 of size 4096 next 96\n",
            "2022-05-04 09:18:39.289372: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e6a000 of size 1024 next 97\n",
            "2022-05-04 09:18:39.289377: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb988e6a400 of size 4194304 next 98\n",
            "2022-05-04 09:18:39.289383: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98926a400 of size 4194304 next 99\n",
            "2022-05-04 09:18:39.289388: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966a400 of size 8192 next 100\n",
            "2022-05-04 09:18:39.289393: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966c400 of size 256 next 101\n",
            "2022-05-04 09:18:39.289399: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966c500 of size 256 next 102\n",
            "2022-05-04 09:18:39.289404: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966c600 of size 256 next 103\n",
            "2022-05-04 09:18:39.289409: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966c700 of size 256 next 104\n",
            "2022-05-04 09:18:39.289414: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966c800 of size 256 next 105\n",
            "2022-05-04 09:18:39.289421: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966c900 of size 512 next 106\n",
            "2022-05-04 09:18:39.289426: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966cb00 of size 2048 next 107\n",
            "2022-05-04 09:18:39.289431: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966d300 of size 1024 next 108\n",
            "2022-05-04 09:18:39.289436: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966d700 of size 4096 next 109\n",
            "2022-05-04 09:18:39.289441: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966e700 of size 1024 next 110\n",
            "2022-05-04 09:18:39.289446: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966eb00 of size 1024 next 111\n",
            "2022-05-04 09:18:39.289452: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98966ef00 of size 4194304 next 112\n",
            "2022-05-04 09:18:39.289458: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a6ef00 of size 256 next 113\n",
            "2022-05-04 09:18:39.289463: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a6f000 of size 1024 next 114\n",
            "2022-05-04 09:18:39.289469: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a6f400 of size 65536 next 115\n",
            "2022-05-04 09:18:39.289475: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a7f400 of size 65536 next 116\n",
            "2022-05-04 09:18:39.289480: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a8f400 of size 1024 next 117\n",
            "2022-05-04 09:18:39.289486: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a8f800 of size 2048 next 118\n",
            "2022-05-04 09:18:39.289491: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a90000 of size 512 next 119\n",
            "2022-05-04 09:18:39.289497: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989a90200 of size 1048576 next 120\n",
            "2022-05-04 09:18:39.289504: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989b90200 of size 1024 next 121\n",
            "2022-05-04 09:18:39.289509: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989b90600 of size 2048 next 122\n",
            "2022-05-04 09:18:39.289516: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb989b90e00 of size 9437184 next 123\n",
            "2022-05-04 09:18:39.289523: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a490e00 of size 256 next 124\n",
            "2022-05-04 09:18:39.289528: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a490f00 of size 2048 next 125\n",
            "2022-05-04 09:18:39.289534: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a491700 of size 589824 next 126\n",
            "2022-05-04 09:18:39.289540: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a521700 of size 512 next 127\n",
            "2022-05-04 09:18:39.289546: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a521900 of size 2048 next 128\n",
            "2022-05-04 09:18:39.289551: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a522100 of size 589824 next 129\n",
            "2022-05-04 09:18:39.289560: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a5b2100 of size 1048576 next 130\n",
            "2022-05-04 09:18:39.289566: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a6b2100 of size 1048576 next 131\n",
            "2022-05-04 09:18:39.289571: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b2100 of size 1024 next 132\n",
            "2022-05-04 09:18:39.289576: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b2500 of size 8192 next 133\n",
            "2022-05-04 09:18:39.289581: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b4500 of size 2048 next 134\n",
            "2022-05-04 09:18:39.289586: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b4d00 of size 1024 next 135\n",
            "2022-05-04 09:18:39.289591: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b5100 of size 1024 next 136\n",
            "2022-05-04 09:18:39.289596: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b5500 of size 512 next 137\n",
            "2022-05-04 09:18:39.289601: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b5700 of size 2048 next 138\n",
            "2022-05-04 09:18:39.289606: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b5f00 of size 2048 next 139\n",
            "2022-05-04 09:18:39.289611: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b6700 of size 4096 next 140\n",
            "2022-05-04 09:18:39.289616: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98a7b7700 of size 9437184 next 141\n",
            "2022-05-04 09:18:39.289621: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b0b7700 of size 8192 next 142\n",
            "2022-05-04 09:18:39.289627: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b0b9700 of size 256 next 143\n",
            "2022-05-04 09:18:39.289632: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b0b9800 of size 1024 next 144\n",
            "2022-05-04 09:18:39.289637: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b0b9c00 of size 1048576 next 145\n",
            "2022-05-04 09:18:39.289642: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b1b9c00 of size 1048576 next 146\n",
            "2022-05-04 09:18:39.289647: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b2b9c00 of size 4096 next 147\n",
            "2022-05-04 09:18:39.289652: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b2bac00 of size 1024 next 148\n",
            "2022-05-04 09:18:39.289657: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b2bb000 of size 262144 next 149\n",
            "2022-05-04 09:18:39.289663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b2fb000 of size 2359296 next 150\n",
            "2022-05-04 09:18:39.289668: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b53b000 of size 4096 next 151\n",
            "2022-05-04 09:18:39.289673: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b53c000 of size 4096 next 152\n",
            "2022-05-04 09:18:39.289678: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b53d000 of size 8192 next 153\n",
            "2022-05-04 09:18:39.289683: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98b53f000 of size 9437184 next 154\n",
            "2022-05-04 09:18:39.289688: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be3f000 of size 512 next 155\n",
            "2022-05-04 09:18:39.289693: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be3f200 of size 16384 next 156\n",
            "2022-05-04 09:18:39.289699: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be43200 of size 37632 next 157\n",
            "2022-05-04 09:18:39.289704: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be4c500 of size 256 next 158\n",
            "2022-05-04 09:18:39.289709: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be4c600 of size 256 next 159\n",
            "2022-05-04 09:18:39.289714: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be4c700 of size 1024 next 160\n",
            "2022-05-04 09:18:39.289719: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be4cb00 of size 262144 next 161\n",
            "2022-05-04 09:18:39.289724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be8cb00 of size 4096 next 162\n",
            "2022-05-04 09:18:39.289729: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be8db00 of size 1024 next 163\n",
            "2022-05-04 09:18:39.289734: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be8df00 of size 1024 next 164\n",
            "2022-05-04 09:18:39.289739: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be8e300 of size 4096 next 165\n",
            "2022-05-04 09:18:39.289745: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98be8f300 of size 262144 next 166\n",
            "2022-05-04 09:18:39.289750: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98becf300 of size 512 next 167\n",
            "2022-05-04 09:18:39.289755: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98becf500 of size 2048 next 168\n",
            "2022-05-04 09:18:39.289760: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98becfd00 of size 1024 next 169\n",
            "2022-05-04 09:18:39.289765: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98bed0100 of size 4096 next 170\n",
            "2022-05-04 09:18:39.289770: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98bed1100 of size 2359296 next 171\n",
            "2022-05-04 09:18:39.289775: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c111100 of size 4096 next 172\n",
            "2022-05-04 09:18:39.289781: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c112100 of size 8192 next 173\n",
            "2022-05-04 09:18:39.289786: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c114100 of size 4096 next 174\n",
            "2022-05-04 09:18:39.289791: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c115100 of size 2048 next 175\n",
            "2022-05-04 09:18:39.289796: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c115900 of size 256 next 176\n",
            "2022-05-04 09:18:39.289801: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c115a00 of size 589824 next 177\n",
            "2022-05-04 09:18:39.289806: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c1a5a00 of size 2048 next 178\n",
            "2022-05-04 09:18:39.289811: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c1a6200 of size 2097152 next 179\n",
            "2022-05-04 09:18:39.289816: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c3a6200 of size 1024 next 180\n",
            "2022-05-04 09:18:39.289821: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c3a6600 of size 1024 next 181\n",
            "2022-05-04 09:18:39.289826: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c3a6a00 of size 2359296 next 182\n",
            "2022-05-04 09:18:39.289832: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c5e6a00 of size 1024 next 183\n",
            "2022-05-04 09:18:39.289837: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c5e6e00 of size 2359296 next 184\n",
            "2022-05-04 09:18:39.289841: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c826e00 of size 2048 next 185\n",
            "2022-05-04 09:18:39.289846: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c827600 of size 2048 next 186\n",
            "2022-05-04 09:18:39.289850: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c827e00 of size 256 next 187\n",
            "2022-05-04 09:18:39.289855: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c827f00 of size 512 next 188\n",
            "2022-05-04 09:18:39.289859: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98c828100 of size 2359296 next 189\n",
            "2022-05-04 09:18:39.289864: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ca68100 of size 1024 next 190\n",
            "2022-05-04 09:18:39.289868: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ca68500 of size 512 next 191\n",
            "2022-05-04 09:18:39.289873: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ca68700 of size 8192 next 192\n",
            "2022-05-04 09:18:39.289877: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ca6a700 of size 8192 next 193\n",
            "2022-05-04 09:18:39.289881: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ca6c700 of size 4194304 next 194\n",
            "2022-05-04 09:18:39.289886: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce6c700 of size 4096 next 195\n",
            "2022-05-04 09:18:39.289890: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce6d700 of size 256 next 196\n",
            "2022-05-04 09:18:39.289895: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce6d800 of size 1024 next 197\n",
            "2022-05-04 09:18:39.289899: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce6dc00 of size 2048 next 198\n",
            "2022-05-04 09:18:39.289904: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce6e400 of size 8192 next 199\n",
            "2022-05-04 09:18:39.289908: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce70400 of size 8192 next 200\n",
            "2022-05-04 09:18:39.289913: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce72400 of size 256 next 201\n",
            "2022-05-04 09:18:39.289917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce72500 of size 256 next 202\n",
            "2022-05-04 09:18:39.289922: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce72600 of size 256 next 203\n",
            "2022-05-04 09:18:39.289926: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce72700 of size 1024 next 204\n",
            "2022-05-04 09:18:39.289931: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce72b00 of size 512 next 205\n",
            "2022-05-04 09:18:39.289936: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ce72d00 of size 524288 next 206\n",
            "2022-05-04 09:18:39.289941: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cef2d00 of size 524288 next 207\n",
            "2022-05-04 09:18:39.289945: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cf72d00 of size 4096 next 208\n",
            "2022-05-04 09:18:39.289950: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cf73d00 of size 2048 next 209\n",
            "2022-05-04 09:18:39.289955: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cf74500 of size 2048 next 210\n",
            "2022-05-04 09:18:39.289959: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cf74d00 of size 65536 next 211\n",
            "2022-05-04 09:18:39.289964: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cf84d00 of size 256 next 212\n",
            "2022-05-04 09:18:39.289968: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cf84e00 of size 147456 next 213\n",
            "2022-05-04 09:18:39.289973: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa8e00 of size 1024 next 214\n",
            "2022-05-04 09:18:39.289978: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9200 of size 256 next 215\n",
            "2022-05-04 09:18:39.289982: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9300 of size 512 next 216\n",
            "2022-05-04 09:18:39.289987: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9500 of size 512 next 217\n",
            "2022-05-04 09:18:39.289991: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9700 of size 512 next 218\n",
            "2022-05-04 09:18:39.289996: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9900 of size 512 next 219\n",
            "2022-05-04 09:18:39.290001: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9b00 of size 512 next 220\n",
            "2022-05-04 09:18:39.290005: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfa9d00 of size 2048 next 221\n",
            "2022-05-04 09:18:39.290010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfaa500 of size 4096 next 222\n",
            "2022-05-04 09:18:39.290014: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfab500 of size 256 next 223\n",
            "2022-05-04 09:18:39.290019: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfab600 of size 1024 next 224\n",
            "2022-05-04 09:18:39.290024: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfaba00 of size 512 next 225\n",
            "2022-05-04 09:18:39.290028: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfabc00 of size 1024 next 226\n",
            "2022-05-04 09:18:39.290033: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfac000 of size 1024 next 227\n",
            "2022-05-04 09:18:39.290037: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfac400 of size 256 next 228\n",
            "2022-05-04 09:18:39.290041: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfac500 of size 512 next 229\n",
            "2022-05-04 09:18:39.290044: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfac700 of size 2048 next 230\n",
            "2022-05-04 09:18:39.290048: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfacf00 of size 512 next 231\n",
            "2022-05-04 09:18:39.290052: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfad100 of size 1024 next 232\n",
            "2022-05-04 09:18:39.290055: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfad500 of size 4096 next 233\n",
            "2022-05-04 09:18:39.290059: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfae500 of size 4096 next 234\n",
            "2022-05-04 09:18:39.290063: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfaf500 of size 1024 next 235\n",
            "2022-05-04 09:18:39.290067: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfaf900 of size 2048 next 236\n",
            "2022-05-04 09:18:39.290070: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfb0100 of size 1024 next 237\n",
            "2022-05-04 09:18:39.290074: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfb0500 of size 2048 next 238\n",
            "2022-05-04 09:18:39.290078: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfb0d00 of size 2048 next 239\n",
            "2022-05-04 09:18:39.290082: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfb1500 of size 512 next 240\n",
            "2022-05-04 09:18:39.290085: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfb1700 of size 1024 next 241\n",
            "2022-05-04 09:18:39.290089: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98cfb1b00 of size 8388608 next 242\n",
            "2022-05-04 09:18:39.290093: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b1b00 of size 512 next 243\n",
            "2022-05-04 09:18:39.290097: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b1d00 of size 4096 next 244\n",
            "2022-05-04 09:18:39.290100: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b2d00 of size 1024 next 245\n",
            "2022-05-04 09:18:39.290104: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b3100 of size 4096 next 246\n",
            "2022-05-04 09:18:39.290108: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b4100 of size 4096 next 247\n",
            "2022-05-04 09:18:39.290112: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b5100 of size 1024 next 248\n",
            "2022-05-04 09:18:39.290115: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b5500 of size 8192 next 249\n",
            "2022-05-04 09:18:39.290119: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b7500 of size 2048 next 250\n",
            "2022-05-04 09:18:39.290122: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d7b7d00 of size 1048576 next 251\n",
            "2022-05-04 09:18:39.290126: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8b7d00 of size 147456 next 252\n",
            "2022-05-04 09:18:39.290131: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8dbd00 of size 1024 next 253\n",
            "2022-05-04 09:18:39.290136: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8dc100 of size 2048 next 254\n",
            "2022-05-04 09:18:39.290142: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8dc900 of size 2048 next 255\n",
            "2022-05-04 09:18:39.290147: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8dd100 of size 512 next 256\n",
            "2022-05-04 09:18:39.290151: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8dd300 of size 1024 next 257\n",
            "2022-05-04 09:18:39.290156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8dd700 of size 4096 next 258\n",
            "2022-05-04 09:18:39.290161: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8de700 of size 2048 next 259\n",
            "2022-05-04 09:18:39.290166: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d8def00 of size 1048576 next 260\n",
            "2022-05-04 09:18:39.290172: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9def00 of size 1024 next 261\n",
            "2022-05-04 09:18:39.290177: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9df300 of size 4096 next 262\n",
            "2022-05-04 09:18:39.290182: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e0300 of size 1024 next 263\n",
            "2022-05-04 09:18:39.290187: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e0700 of size 256 next 264\n",
            "2022-05-04 09:18:39.290194: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e0800 of size 512 next 265\n",
            "2022-05-04 09:18:39.290200: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e0a00 of size 512 next 266\n",
            "2022-05-04 09:18:39.290205: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e0c00 of size 512 next 267\n",
            "2022-05-04 09:18:39.290210: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e0e00 of size 4096 next 268\n",
            "2022-05-04 09:18:39.290216: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e1e00 of size 1024 next 269\n",
            "2022-05-04 09:18:39.290222: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e2200 of size 1024 next 270\n",
            "2022-05-04 09:18:39.290228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e2600 of size 2048 next 271\n",
            "2022-05-04 09:18:39.290241: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e2e00 of size 8192 next 272\n",
            "2022-05-04 09:18:39.290247: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e4e00 of size 256 next 273\n",
            "2022-05-04 09:18:39.290252: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e4f00 of size 256 next 274\n",
            "2022-05-04 09:18:39.290257: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5000 of size 256 next 275\n",
            "2022-05-04 09:18:39.290262: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5100 of size 256 next 276\n",
            "2022-05-04 09:18:39.290267: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5200 of size 256 next 277\n",
            "2022-05-04 09:18:39.290271: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5300 of size 256 next 280\n",
            "2022-05-04 09:18:39.290277: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5400 of size 256 next 281\n",
            "2022-05-04 09:18:39.290284: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5500 of size 256 next 282\n",
            "2022-05-04 09:18:39.290289: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5600 of size 256 next 283\n",
            "2022-05-04 09:18:39.290295: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5700 of size 256 next 284\n",
            "2022-05-04 09:18:39.290300: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5800 of size 256 next 285\n",
            "2022-05-04 09:18:39.290306: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5900 of size 256 next 286\n",
            "2022-05-04 09:18:39.290312: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5a00 of size 256 next 287\n",
            "2022-05-04 09:18:39.290317: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5b00 of size 256 next 288\n",
            "2022-05-04 09:18:39.290321: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5c00 of size 256 next 289\n",
            "2022-05-04 09:18:39.290325: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98d9e5d00 of size 161024 next 278\n",
            "2022-05-04 09:18:39.290329: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da0d200 of size 81920 next 279\n",
            "2022-05-04 09:18:39.290333: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da21200 of size 256 next 290\n",
            "2022-05-04 09:18:39.290337: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da21300 of size 81920 next 291\n",
            "2022-05-04 09:18:39.290340: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35300 of size 256 next 292\n",
            "2022-05-04 09:18:39.290344: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35400 of size 256 next 293\n",
            "2022-05-04 09:18:39.290348: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35500 of size 256 next 294\n",
            "2022-05-04 09:18:39.290351: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35600 of size 256 next 295\n",
            "2022-05-04 09:18:39.290355: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35700 of size 256 next 296\n",
            "2022-05-04 09:18:39.290359: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35800 of size 256 next 297\n",
            "2022-05-04 09:18:39.290362: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35900 of size 256 next 298\n",
            "2022-05-04 09:18:39.290366: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35a00 of size 256 next 299\n",
            "2022-05-04 09:18:39.290370: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35b00 of size 256 next 300\n",
            "2022-05-04 09:18:39.290373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35c00 of size 256 next 301\n",
            "2022-05-04 09:18:39.290377: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35d00 of size 256 next 302\n",
            "2022-05-04 09:18:39.290381: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98da35e00 of size 256 next 303\n",
            "2022-05-04 09:18:39.290384: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fb98da35f00 of size 19267584 next 304\n",
            "2022-05-04 09:18:39.290388: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ec95f00 of size 1280 next 305\n",
            "2022-05-04 09:18:39.290392: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fb98ec96400 of size 256 next 306\n",
            "2022-05-04 09:18:39.290396: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ec96500 of size 256 next 307\n",
            "2022-05-04 09:18:39.290399: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98ec96600 of size 256 next 308\n",
            "2022-05-04 09:18:39.290403: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fb98ec96700 of size 20313600 next 309\n",
            "2022-05-04 09:18:39.290407: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fb98fff5d00 of size 38970112 next 18446744073709551615\n",
            "2022-05-04 09:18:39.290411: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
            "2022-05-04 09:18:39.290417: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 60 Chunks of size 256 totalling 15.0KiB\n",
            "2022-05-04 09:18:39.290422: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 32 Chunks of size 512 totalling 16.0KiB\n",
            "2022-05-04 09:18:39.290427: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 64 Chunks of size 1024 totalling 64.0KiB\n",
            "2022-05-04 09:18:39.290431: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1280 totalling 2.5KiB\n",
            "2022-05-04 09:18:39.290435: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 45 Chunks of size 2048 totalling 90.0KiB\n",
            "2022-05-04 09:18:39.290440: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 31 Chunks of size 4096 totalling 124.0KiB\n",
            "2022-05-04 09:18:39.290444: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 16 Chunks of size 8192 totalling 128.0KiB\n",
            "2022-05-04 09:18:39.290448: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 16384 totalling 16.0KiB\n",
            "2022-05-04 09:18:39.290453: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 37632 totalling 36.8KiB\n",
            "2022-05-04 09:18:39.290457: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 65536 totalling 384.0KiB\n",
            "2022-05-04 09:18:39.290462: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 81920 totalling 160.0KiB\n",
            "2022-05-04 09:18:39.290466: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 131072 totalling 128.0KiB\n",
            "2022-05-04 09:18:39.290470: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 147456 totalling 432.0KiB\n",
            "2022-05-04 09:18:39.290475: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 161024 totalling 157.2KiB\n",
            "2022-05-04 09:18:39.290479: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 7 Chunks of size 262144 totalling 1.75MiB\n",
            "2022-05-04 09:18:39.290483: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 524288 totalling 1.00MiB\n",
            "2022-05-04 09:18:39.290488: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 4 Chunks of size 589824 totalling 2.25MiB\n",
            "2022-05-04 09:18:39.290492: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 11 Chunks of size 1048576 totalling 11.00MiB\n",
            "2022-05-04 09:18:39.290496: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 2097152 totalling 4.00MiB\n",
            "2022-05-04 09:18:39.290501: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 2359296 totalling 13.50MiB\n",
            "2022-05-04 09:18:39.290505: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 5 Chunks of size 4194304 totalling 20.00MiB\n",
            "2022-05-04 09:18:39.290509: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8388608 totalling 8.00MiB\n",
            "2022-05-04 09:18:39.290514: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 9437184 totalling 27.00MiB\n",
            "2022-05-04 09:18:39.290518: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 38970112 totalling 37.16MiB\n",
            "2022-05-04 09:18:39.290522: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 127.38MiB\n",
            "2022-05-04 09:18:39.290527: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 173146112 memory_limit_: 173146112 available bytes: 0 curr_region_allocation_bytes_: 346292224\n",
            "2022-05-04 09:18:39.290534: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
            "Limit:                       173146112\n",
            "InUse:                       133564672\n",
            "MaxInUse:                    153878528\n",
            "NumAllocs:                         317\n",
            "MaxAllocSize:                 38970112\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2022-05-04 09:18:39.290542: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *******************************************************__________*___________*************xxxxxxxxxx\n",
            "2022-05-04 09:18:39.290579: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:684 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[32,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node predict/resnet_v2_50/conv1/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_17797]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[1;32m/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=0'>1</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=1'>2</a>\u001b[0m resnet_history \u001b[39m=\u001b[39m resnet_model\u001b[39m.\u001b[39;49mfit(train_data_10_percent,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=2'>3</a>\u001b[0m                                   epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=3'>4</a>\u001b[0m                                   steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_data_10_percent),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=4'>5</a>\u001b[0m                                   validation_data\u001b[39m=\u001b[39;49mtest_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=5'>6</a>\u001b[0m                                   validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(test_data),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=6'>7</a>\u001b[0m                                   \u001b[39m# Add TensorBoard callback to model (callbacks parameter takes a list)\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=7'>8</a>\u001b[0m                                   callbacks\u001b[39m=\u001b[39;49m[create_tensorboard_callback(dir_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtensorflow_hub\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m# save experiment logs here\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ahsan/tensorflow-learning-master/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb#ch0000025?line=8'>9</a>\u001b[0m                                                                          experiment_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mresnet50V2\u001b[39;49m\u001b[39m\"\u001b[39;49m)])\n",
            "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/ahsan/anaconda3/envs/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[32,64,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node predict/resnet_v2_50/conv1/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_17797]"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n",
        "                                                                         experiment_name=\"resnet50V2\")]) # name of log files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5SuOe672UJi"
      },
      "source": [
        "Wow! \n",
        "\n",
        "It seems that after only 5 epochs, the ResNetV250 feature extraction model was able to blow any of the architectures we made out of the water, achieving around 90% accuracy on the training set and nearly 80% accuracy on the test set...**with only 10 percent of the training images!**\n",
        "\n",
        "That goes to show the power of transfer learning. And it's one of the main reasons whenever you're trying to model your own datasets, you should look into what pretrained models already exist.\n",
        "\n",
        "Let's check out our model's training curves using our `plot_loss_curves` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot2QPj41ODCQ"
      },
      "outputs": [],
      "source": [
        "# If you wanted to, you could really turn this into a helper function to load in with a helper.py script...\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "ywQ9Wr9UODJ_",
        "outputId": "a225ebca-4308-4175-95e9-849c4bd21ab4"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(resnet_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BGVFEIi3_CT"
      },
      "source": [
        "And what about a summary of our model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aps1FV4qWrZb",
        "outputId": "306849a0-a3a2-4404-d046-eceb7186871f"
      },
      "outputs": [],
      "source": [
        "# Resnet summary \n",
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okdbmBA0SgCb"
      },
      "source": [
        "You can see the power of TensorFlow Hub here. The feature extraction layer has 23,564,800 parameters which are prelearned patterns the model has already learned on the ImageNet dataset. Since we set `trainable=False`, these patterns remain frozen (non-trainable) during training.\n",
        "\n",
        "This means during training the model updates the 20,490 parameters in the output layer to suit our dataset.\n",
        "\n",
        "Okay, we've trained a ResNetV250 model, time to do the same with EfficientNetB0 model.\n",
        "\n",
        "The setup will be the exact same as before, except for the `model_url` parameter in the `create_model()` function and the `experiment_name` parameter in the `create_tensorboard_callback()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrGi-CpMXHav",
        "outputId": "251ab535-7852-4e05-c356-dba75c37ba34"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "efficientnet_model = create_model(model_url=efficientnet_url, # use EfficientNetB0 TensorFlow Hub URL\n",
        "                                  num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile EfficientNet model\n",
        "efficientnet_model.compile(loss='categorical_crossentropy',\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "# Fit EfficientNet model \n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent, # only use 10% of training data\n",
        "                                              epochs=5, # train for 5 epochs\n",
        "                                              steps_per_epoch=len(train_data_10_percent),\n",
        "                                              validation_data=test_data,\n",
        "                                              validation_steps=len(test_data),\n",
        "                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", \n",
        "                                                                                     # Track logs under different experiment name\n",
        "                                                                                     experiment_name=\"efficientnetB0\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMbtls4C57Dr"
      },
      "source": [
        "Holy smokes! The EfficientNetB0 model does even better than the ResNetV250 model! Achieving over 85% accuracy on the test set...again **with only 10% of the training data**.\n",
        "\n",
        "How cool is that?\n",
        "\n",
        "With a couple of lines of code we're able to leverage state of the art models and adjust them to our own use case.\n",
        "\n",
        "Let's check out the loss curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "8UzgNYFdODRB",
        "outputId": "24ffc097-9536-4ff7-f739-51bf2cf883a8"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(efficientnet_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDi4i0H16tSa"
      },
      "source": [
        "From the look of the EfficientNetB0 model's loss curves, it looks like if we kept training our model for longer, it might improve even further. Perhaps that's something you might want to try?\n",
        "\n",
        "Let's check out the model summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clJzUbKpODXA",
        "outputId": "3538504b-1cc9-4569-db9e-b191ea37d20f"
      },
      "outputs": [],
      "source": [
        "efficientnet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHTMjJG07ElO"
      },
      "source": [
        "It seems despite having over four times less parameters (4,049,564 vs. 23,564,800) than the ResNet50V2 extraction layer, the  EfficientNetB0 feature extraction layer yields better performance. Now it's clear where the \"efficient\" name came from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV_ZWKC8SkE_"
      },
      "source": [
        "## Comparing models using TensorBoard\n",
        "\n",
        "Alright, even though we've already compared the performance of our two models by looking at the accuracy scores. But what if you had more than two models? \n",
        "\n",
        "That's where an experiment tracking tool like [TensorBoard](https://www.tensorflow.org/tensorboard) (preinstalled in Google Colab) comes in.\n",
        "\n",
        "The good thing is, since we set up a TensorBoard callback, all of our model's training logs have been saved automatically. To visualize them, we can upload the results to [TensorBoard.dev](https://tensorboard.dev/).\n",
        "\n",
        "Uploading your results to TensorBoard.dev enables you to track and share multiple different modelling experiments. So if you needed to show someone your results, you could send them a link to your TensorBoard.dev as well as the accompanying Colab notebook.\n",
        "\n",
        "> ðŸ”‘ **Note:** These experiments are public, do not upload sensitive data. You can delete experiments if needed.\n",
        "\n",
        "### Uploading experiments to TensorBoard\n",
        "\n",
        "To upload a series of TensorFlow logs to TensorBoard, we can use the following command:\n",
        "\n",
        "```\n",
        "Upload TensorBoard dev records\n",
        "\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EfficientNetB0 vs. ResNet50V2\" \\ \n",
        "  --description \"Comparing two different TF Hub feature extraction models architectures using 10% of training images\" \\ \n",
        "  --one_shot\n",
        "```\n",
        "\n",
        "Where:\n",
        "* `--logdir` is the target upload directory\n",
        "* `--name` is the name of the experiment\n",
        "* `--description` is a brief description of the experiment\n",
        "* `--one_shot` exits the TensorBoard uploader once uploading is finished\n",
        "\n",
        "Running the `tensorboard dev upload` command will first ask you to authorize the upload to TensorBoard.dev. After you've authorized the upload, your log files will be uploaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "tbKgWdIVNncW",
        "outputId": "e344cf7c-7064-484d-f31b-4079735dc921"
      },
      "outputs": [],
      "source": [
        "# Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EfficientNetB0 vs. ResNet50V2\" \\\n",
        "  --description \"Comparing two different TF Hub feature extraction models architectures using 10% of training images\" \\\n",
        "  --one_shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlVfmBdBOPvf"
      },
      "source": [
        "Every time you upload something to TensorBoad.dev you'll get a new experiment ID. The experiment ID will look something like this: https://tensorboard.dev/experiment/73taSKxXQeGPQsNBcVvY3g/ (this is the actual experiment from this notebook).\n",
        "\n",
        "If you upload the same directory again, you'll get a new experiment ID to go along with it.\n",
        "\n",
        "This means to track your experiments, you may want to look into how you name your uploads. That way when you find them on TensorBoard.dev you can tell what happened during each experiment (e.g. \"efficientnet0_10_percent_data\").\n",
        "\n",
        "### Listing experiments you've saved to TensorBoard\n",
        "\n",
        "To see all of the experiments you've uploaded you can use the command:\n",
        "\n",
        "```tensorboard dev list```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "sDamroaMOFJx",
        "outputId": "d086e0da-e091-4504-87d6-a50aa4636577"
      },
      "outputs": [],
      "source": [
        "# Check out experiments\n",
        "!tensorboard dev list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLUjm-xADQ4"
      },
      "source": [
        "### Deleting experiments from TensorBoard\n",
        "\n",
        "Remember, all uploads to TensorBoard.dev are public, so to delete an experiment you can use the command:\n",
        "\n",
        "`tensorboard dev delete --experiment_id [INSERT_EXPERIMENT_ID]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "qj69wuAlT-xS",
        "outputId": "fcc4a104-85eb-4f66-aa43-8bc25b75a51a"
      },
      "outputs": [],
      "source": [
        "# Delete an experiment\n",
        "!tensorboard dev delete --experiment_id n6kd8XZ3Rdy1jSgSLH5WjA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Oov6qKvbU1lL",
        "outputId": "9d2997d3-7278-4290-e8b8-f4fb2c9aab76"
      },
      "outputs": [],
      "source": [
        "# Check to see if experiments still exist\n",
        "!tensorboard dev list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLvUjrL2Y1Ed"
      },
      "source": [
        "## ðŸ›  Exercises\n",
        "\n",
        "1. Build and fit a model using the same data we have here but with the MobileNetV2 architecture feature extraction ([`mobilenet_v2_100_224/feature_vector`](https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4)) from TensorFlow Hub, how does it perform compared to our other models?\n",
        "2. Name 3 different image classification models on TensorFlow Hub that we haven't used.\n",
        "3. Build a model to classify images of two different things you've taken photos of.\n",
        "  * You can use any feature extraction layer from TensorFlow Hub you like for this.\n",
        "  * You should aim to have at least 10 images of each class, for example to build a fridge versus oven classifier, you'll want 10 images of fridges and 10 images of ovens.\n",
        "4. What is the current best performing model on ImageNet?\n",
        "  * Hint: you might want to check [sotabench.com](https://www.sotabench.com) for this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_YxwuhfRzD5"
      },
      "source": [
        "## ðŸ“– Extra-curriculum\n",
        "\n",
        "* Read through the [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning) and define the main two types of transfer learning in your own words.\n",
        "* Go through the [Transfer Learning with TensorFlow Hub tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub) on the TensorFlow website and rewrite all of the code yourself into a new Google Colab notebook making comments about what each step does along the way.\n",
        "* We haven't covered fine-tuning with TensorFlow Hub in this notebook, but if you'd like to know more, go through the [fine-tuning a TensorFlow Hub model tutorial](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) on the TensorFlow homepage.How to fine-tune a tensorflow hub model:  \n",
        "* Look into [experiment tracking with Weights & Biases](https://www.wandb.com/experiment-tracking), how could you integrate it with our existing TensorBoard logs?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPTOThku3umT+sZBpj2+yq/",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
